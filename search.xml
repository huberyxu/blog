<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Druid-架构]]></title>
    <url>%2F2018%2F02%2F12%2FDruid-%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[架构体系Druid集群由不同类型的节点组成，每个节点类型被设计用于执行特定的一组事情。我们认为，这种设计将关注点分离，简化了整个系统的复杂性，不同的节点类型之间相互独立，而且它们之间的交互很少。因此，集群内通信故障对数据可用性的影响最小。 为了解决复杂的数据分析问题，不同的节点类型聚在一起形成一个完整的工作系统。Druid这个名字来自于许多角色扮演游戏中的德鲁伊，它是一个变形者，能够在一个群体中扮演各种不同的角色。德鲁伊集群中数据的组成和数据流如图1所示。 Real-time NodesReal-time Nodes的功能是”数据注入”和”查询事件流”。Event通过这些节点创建索引并立即用于查询。这些节点只关心一些小的时间范围内的Event，并且周期性地将它们在这个小时间范围内收集到的”不可变数据集”并传递给Druid集群中的其他节点，这些节点专门处理一些”不可变数据集”。实时节点利用Zookeeper[19]与其他Druid节点进行协调。这些节点宣告它们的在线状态和它们在Zookeeper中服务的数据。 Real-time Nodes为所有注入的事件在内存中维护的索引缓冲区。这些索引随着事件的注入而递增，索引也可以直接查询。Druid的行为像是基于JVM堆内存的行式存储。为了避免堆溢出问题，Real-time Nodes会周期性地或在达到某个最大行限制后将内存索引持久化到磁盘。这个持久化过程将存储在内存缓冲区中的数据转换为第4节中描述的面向列存储格式。每个持久的索引都是不可变的，Real-time Nodes将持久的索引加载到堆外内存中，这样它们仍然可以被查询。这个过程在[33]中被详细描述，如图2所示。 定期地，每个Real-time Node将调度一个后台任务，搜索所有本地持久化的索引。该任务将这些索引合并在一起，并构建一个不可变的数据块，该数据块包含一个实时节点在一定时间内所接收到的所有事件。我们将此数据块称为“segment”。在转换阶段，实时节点将此段上传至永久备份存储，通常是一个分布式文件系统，如S3[12]或HDFS[36]，而Druid将其称为“deep storage”。ingest、persist、merge和handoff步骤都是流畅的;在任何过程中都没有数据丢失。 图3说明了Real-time Node的操作。节点从13:37开始，只接受当前小时或下一个小时的事件。当事件被注入时，该节点宣布它将从13:00到14:00的时间段内服务一个数据段。每10分钟(持久化周期是可配置的)，节点将刷新并将其内存缓冲区保存到磁盘。在临近结束时，节点很可能会在看到14:00到15:00之间的事件。当出现这种情况时，节点准备为下一个小时提供数据，并创建一个新的内存索引。然后，节点宣布它也从14:00到15:00服务一个段。从13:00到14:00，节点不会立即合并持久索引，而是等待从13:00到14:00的离散事件的可配置窗口期。这个窗口期最小化了在事件交付过程中数据丢失的风险。当窗口期结束，节点合并从13:00到14:00的所有索引到一个不变的段(segment)。一旦这个段在其他Druid集群中被加载并可查询时，实时节点将”下架”13:00到14:00的数据。 可用性和可伸缩性Real-time nodes是数据的使用者，需要一个对应的生产者来提供数据流。一般来说，对于数据耐用性的目的，位于生产者和实时节点之间会有一个像Kafka[21]这样的消息总线，如图4所示，实时节点通过从消息总线中读取事件来获取数据，从事件创建到事件消耗的时间通常为数百毫秒。 图4中的消息总线有两个目的。首先，消息总线充当传入事件的缓冲区。像Kafka这样的消息总线维护了位置偏移量——表明了在事件流中，一个消费者(一个实时节点)已经读取了多少。消费者可以通过编程方式更新这些偏移量。实时节点在每次将内存缓冲区保存到磁盘时更新此偏移量。在失败和恢复场景中，如果一个节点没有丢失磁盘，它可以从磁盘重新加载所有持久的索引，并从它所提交的最后偏移量中继续读取事件。从最近的提交点注入事件可以大大减少一个节点的恢复时间。在实践中，我们发现节点在几秒钟内便从这些失败场景中恢复过来。 消息总线的第二个目的是充当单个端点，多个实时节点可以从该端点读取事件。多个实时节点可以从总线上接收相同的事件集合，从而创建事件的复制。在一个场景中，一个节点commit失败并丢失磁盘，复制的流确保没有数据丢失。单个注入端点还允许对数据流进行分区，从而使多个实时节点都能接收到流的一部分。这允许无缝地添加额外的实时节点。在实践中，该模型使最大的Druid生产集群能够以大约500 MB/s(15万Event/s或2 TB/小时)的速度消耗原始数据。 Historical NodesHistorical Nodes功能是加载和服务由实时节点创建的不可变数据块(段)。在许多实际的工作流中，在Druid集群中加载的大多数数据是不可变的，因此，Historical Nodes通常是Druid集群的主要工作人员。Historical Nodes遵循无中心架构，节点之间没有独立的连接点。节点之间没有相互了解，操作上也很简单;它们只知道如何加载、删除和服务“不可变段”。 类似于实时节点，历史节点在Zookeeper声明它们的在线状态和它们服务中的数据。加载和下架段的指令被发送到Zookeeper上，其中包含该segment位于deep storage的位置信息，以及如何解压缩和处理该segment。在历史节点从深度存储中下载特定的段之前，它首先检查一个本地缓存，该缓存维护节点上已经存在的段的信息。如果缓存中不存在某个段的信息，那么历史节点将继续从深度存储中下载该段。这个过程如图5所示。一旦成功完成，该部分将在zookeeper中宣布。此时，该段是可查询的。本地缓存还允许快速更新和重新启动历史节点。在启动时，节点检查它的缓存并立即提供它找到的任何数据。 历史节点可以支持读取一致性，因为它们只处理不可变数据。不可变数据块还支持简单并行化模型:历史节点可以同时扫描和聚合不可变块，而不会阻塞。 Tiers机制历史节点可以分在不同的tiers中，其中给定tiers中的所有节点都是相同配置的。可以为每一tier设置不同的性能和容错参数。节点分层的目的是根据segment的重要性，分配高、低优先级。例如，可以创建一个“hot”级的历史节点，这些节点具有高的内核数和较大的内存容量。可以将“hot”集群配置为更频繁下载访问的数据。一个并行的“cold”集群也可以用不太强大的支持硬件来创建。“cold”集群只包含较少被访问的部分。 可用性历史节点依赖于Zookeeper的段“加载”和“下架”指令。如果Zookeeper变得不可用，那么历史节点就不再能够提供新的数据或删除过时的数据，因为查询是通过HTTP提供的，而历史节点仍然能够响应查询请求，以获取当前服务的数据。这意味着，Zookeeper中断不会影响历史节点上的当前数据可用性。 Broker NodesBroker nodes充当历史和实时节点的查询路由器。Broker节点知晓在Zookeeper中发布的关于哪些段是可查询的以及这些段所在位置的元数据。代理路由传入的查询，这样查询就会命中正确的历史节点或实时节点。Broker节点还将历史和实时节点的部分结果合并，然后将最终合并结果返回给调用者。 缓存Broker nodes包含一个LRU[31, 20]失效策略的缓存。缓存可以使用本地堆内存或外部分布式key/value存储[16]。每当一个broker节点接收到一个查询时，它首先将查询映射到一组segments。某些段的结果可能已经存在于缓存中，不需要重新计算它们。对于缓存中不存在的任何结果，broker节点将向正确的历史和实时节点转发查询。一旦历史节点返回其结果，代理将会将这些结果缓存到一个基础段中以供将来使用。这个过程如图6所示。实时数据永远不会被缓存，因此实时数据的请求将被转发到实时节点。实时数据永远在变化，缓存结果是不可靠的。 缓存还可以额外作为数据可靠性级别。在所有历史节点都失败的情况下，如果缓存中已经存在这些结果，仍然可以查询结果。 可靠性在整个Zookeeper中断的情况下，数据仍然是可查询的。如果broker节点无法与Zookeeper进行通信，它们将使用集群的最后一个memory，并继续将查询转发到实时和历史节点。broker节点假定集群的结构与中断前的结构相同。在实践中，这个可用性模型允许我们的Druid集群在诊断Zookeeper宕机的时候继续为查询服务。 Coordinator NodesDruid Coordinator Nodes（协调节点）主要负责历史节点的数据管理和分配。协调器节点告诉历史节点加载新数据、删除过时数据、复制数据，并将数据移动到负载平衡。Druid使用多版本并发控制交换协议来管理不可变段，以保持稳定的视图。如果任何不可变的segment包含被完全废弃的数据，那么过时的片段就会从集群中删除。协调节点经历了一个领导选举过程，决定运行协调功能的节点。其余的协调节点充当冗余备份。 Coordinator Nodes定期运行以确定集群的当前状态。它通过将集群的期望状态与运行时集群的实际状态进行比较，从而做出决策。与所有Druid节点一样，协调节点维护当前集群信息的Zookeeper连接。协调节点还维护与一个MySQL数据库的连接，该数据库包含额外的操作参数和配置。MySQL数据库中的关键信息之一是包含所有应该由历史节点服务的所有段的列表。这个表可以通过创建段(例如实时节点)的任何服务来更新。MySQL数据库还包含一个规则表，该规则表在集群中管理如何创建、销毁和复制段。 Rules“Rules”管理如何从集群中加载和删除历史片段。”Rules”指示如何将段分配到不同的历史节点tier，以及每个tier中应该存在多少个片段的备份。”Rules”也可能指出何时应该完全从集群中删除段。”Rules”通常设置一段时间。例如，用户可以使用规则将最近的一个月的片段加载到一个“热”集群中，将最近一年的部分划分为“冷”集群，并删除较老的部分。 coordinator nodes从MySQL数据库中的规则表加载一组规则。规则可能是特定于某个数据源的，或者可以配置一个默认的规则集。coordinator nodes将循环遍历所有可用的段，并将每个seg与应用于它的第一条规则相匹配。 Load Balancing在典型的生产环境中，查询常常会命中几十个甚至几百个段。由于每个历史节点都有有限的资源，所以必须在集群之间分配段，以确保集群负载平衡。确定最优的负载分布需要一些关于查询模式和速度的信息。一般情况下，查询涵盖了单个数据源的跨时间间隔的最近段。平均而言，访问较小段的查询速度更快。 这些查询模式建议在更高的速率上复制最近的历史segment，将大量的片段分散到不同的历史节点上，并从不同的数据源中联合定位片段。为了在集群中最优地分配和平衡segments，我们开发了一个基于成本的优化过程，该过程考虑了段数据源、距离和大小。该算法的具体细节超出了本文的范围，可以在以后的文献中讨论。 ReplicationCoordinator nodes可以告诉不同的历史节点加载同一段的副本。历史计算集群的每个tier中复制的数量是完全可配置的。需要高水平容错的设置可以配置为具有大量的副本。备份的段与原始的段相同，并遵循相同的负载分配算法。通过备份段，单个历史节点故障在Druid集群中是透明的。我们使用此属性进行软件升级。我们可以无缝地将一个历史节点脱机，更新它，将其恢复，并对集群中的每个历史节点重复这个过程。在过去的两年里，我们从来没有在我们的Druid集群中进行软件升级。 可靠性Druid协调节点将Zookeeper和MySQL作为外部依赖关系。协调节点依赖于Zookeeper来确定集群中已经存在的历史节点。如果Zookeeper是不可用的，那么协调器将不再能够发送指令来分配、平衡和删除部分。然而，这些操作并不影响数据的可用性。 对MySQL和Zookeeper失败的响应的设计原则是相同的:如果一个负责协作的外部依赖项失败，集群将维持现状。Druid使用MySQL存储操作管理信息和段元数据信息，了解哪些片段应该存在于集群中。如果MySQL宕机，则此信息将无法用于协调节点。然而，这并不意味着数据本身是不可用的。如果协调节点无法与MySQL通信，它们将停止分配新的段并删除过时的部分。在MySQL中断期间，代理、历史和实时节点仍然可以查询。]]></content>
      <categories>
        <category>Druid</category>
      </categories>
      <tags>
        <tag>OLAP</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Druid-背景]]></title>
    <url>%2F2018%2F02%2F12%2FDruid-%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[提出问题Druid最初的设计目的是解决围绕数据注入和探索大量事务事件(日志数据)的问题。这种timeseries形式的数据通常在OLAP中出现，而数据的性质往往非常复杂。例如，考虑表1所示的数据。表1包含在Wikipedia上发生编辑的数据。每次用户编辑Wikipedia中的页面时，都会生成一个关于”编辑”的元数据的事件。 Timestamp Page Username Gender City Characters Added Characters Removed 2011-01-01T01:00:00Z Justin Bieber Boxer Male San Francisco 1800 25 2011-01-01T01:00:00Z Justin Bieber Reach Male Waterloo 2912 42 2011-01-01T02:00:00Z Ke$ha Helz Male Calgary 1953 17 2011-01-01T02:00:00Z Ke$ha Xeno Male Taiyuan 3194 170 此元数据由3个不同的部分组成。首先，有一个时间戳列，指示何时进行编辑。接下来，有一个维度列，指示编辑器(例如编辑的页面、编辑的用户和用户的位置)的各种属性。最后，有一组度量列包含可以聚合的值(通常是数值)，例如在编辑中添加或删除的字符数。我们的目标是快速地对这些数据的下钻和聚集。我们想回答这样的问题:“在旧金山，贾斯汀·比伯在页面上做了多少编辑?”以及“在一个月的时间里，来自Calgary的人们添加的字符的平均数量是多少?”我们还希望对任意维度的任意组合进行查询，以亚秒级延迟返回。 由于现有的开源关系数据库管理系统(RDBMS)和NoSQL键/值存储无法为交互式应用程序提供低延迟的数据输入和查询平台[40]，因此需要使用Druid。在Metamarkets的早期，我们专注于构建一个托管的仪表板，允许用户任意地探索和可视化事件流。数据存储为仪表板提供了强大的支持，使其能够快速返回查询，使数据可视化能够为用户提供交互式体验。 除了查询延迟需求之外，系统还必须是多租户和高可用的。在高度并发的环境中使用了Metamarkets产品。如果一个系统在软件升级或网络故障的情况下无法使用，停机时间将会非常昂贵，而且许多企业不愿意等待。创业公司通常缺乏适当的内部运营管理，因此，宕机往往决定企业的成败。 最后，Metamarkets在早期面临的另一个挑战是允许用户和警报系统在“实时”中做出业务决策。当”一个事件被创建”到”该事件是可查询”的时候，时延就决定了跨部门的各方能够对其系统中潜在的灾难性情况作出反应。流行的开源数据仓库系统，如Hadoop，无法提供我们需要的亚秒数据注入延迟。 多个行业面临数据挖掘、注入和可用性的问题。自从Druid在2012年10月开源之后，它作为一个视频、网络监控、操作监控和在线广告分析平台在多个公司中部署。]]></content>
      <categories>
        <category>Druid</category>
      </categories>
      <tags>
        <tag>OLAP</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Druid-概述]]></title>
    <url>%2F2018%2F02%2F12%2FDruid-%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[概述Druid是一个用于大规模数据集的实时分析处理的数据存储系统。该系统结合了列存储、分布式的、无共享的体系结构，高效的索引能够支持10亿行数据分析查询的亚秒级响应。在本文中，我们描述了Druid的架构，以及它如何支持快速聚合，灵活的过滤器，以及低延迟的数据注入。Categories and Subject DescriptorsH.2.4 [Database Management]: Systems—Distributed databases关键字distributed; real-time; fault-tolerant; highly available; open source; analytics; column-oriented; OLAP 简介近年来，互联网技术的迅猛发展使机器生成的事件激增。单独来说，这些事件包含的有用信息非常少，而且价值很低。考虑到从大量数据中提取有价值的数据所需的时间和资源，许多公司愿意放弃这些数据。尽管已经建立了基础设施来处理基于事件的数据(例如IBM的Netezza[37]、HP的Vertica[5]和EMC的Greenplum[29])，但它们在很大程度上以高价出售，而且只针对那些能够支付得起的公司。 几年前，谷歌引入了MapReduce[11]作为其利用商品硬件的机制来索引网络和分析日志。Hadoop[36]项目很快就完成了，并且很大程度上是基于最初的MapReduce理论而形成的。Hadoop目前部署在许多组织中，以存储和分析大量的日志数据。Hadoop帮助公司将其低价值的事件流转化为高价值的聚合，用于各种应用程序，如商业智能和测试。 与许多伟大的系统一样，Hadoop已经打开了我们的视野，也让我们看到新的问题。具体来说，Hadoop擅长存储和提供大量数据，但是它不能保证数据访问的速度有多快。此外，尽管Hadoop是一个高度可用的系统，但是在大量并发负载下性能会降低。最后，尽管Hadoop可以很好地存储数据，但它并没有对数据进行优化，使数据立即可读。 在开发Metamarkets产品的早期，我们遇到了这些问题，并认识到Hadoop是一个很好的后台处理、批处理和数据仓库系统。但是，作为一个在高度一致的租户环境(1000+用户)中具有产品级保证的公司，查询性能和数据可用性方面，Hadoop并不能满足我们的需求。 我们探索了不同的解决方案，在尝试了关系数据库管理系统和NoSQL技术架构之后，我们得出了这样的结论:在开源世界中没有任何东西可以完全满足我们的需求。我们最终创建了Druid，一个开源的、分布式的、基于列的、实时的分析数据存储。在许多方面，Druid与其他OLAP系统(30、35、22)、在交互查询系统[28]、内存数据库[14]以及广为人知的分布式数据存储(7、12、23)有相似之处。在分布式和查询模型上也借鉴了当前的生成搜索基础结构[25,3,4]。本文描述了Druid的架构，探索了在创建系统的过程中所做的各种决策设计，它为托管服务提供了动力，并试图帮助任何一个面临类似问题的人。Druid被部署在几个技术公司的生产环境中中。本文的结构如下:首先第2节中描述Druid解决的问题。接下来，第3节我们将从数据流角度详细介绍系统架构。在第4节中，我们讨论如何以及为什么数据转换成二进制格式。第5节中简要描述了查询API，并在第6节中展示了性能结果。最后，我们将从第7节中运行Druid、第8节中总结经验。]]></content>
      <categories>
        <category>Druid</category>
      </categories>
      <tags>
        <tag>OLAP</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序 / INTRO]]></title>
    <url>%2F2018%2F02%2F10%2F%E5%BA%8F-INTRO%2F</url>
    <content type="text"><![CDATA[我们要有最朴素的生活 与最遥远的梦想即使明日天寒地冻 路远马亡 WELCOME HUBERY’S POLARIS 这里是徐海滨的博客 主要更新一些技术文章、个人作品 请持续关注哟~~~ 比心]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ganglia原理介绍、安装使用]]></title>
    <url>%2F2018%2F02%2F10%2FGanglia%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E3%80%81%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Ganglia简介：Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含gmond、gmetad以及一个Web前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。 每台计算机都运行一个收集和发送度量数据的名为 gmond 的守护进程。接收所有度量数据的主机可以显示这些数据并且可以将这些数据的精简表单传递到层次结构中。正因为有这种层次结构模式，才使得 Ganglia 可以实现良好的扩展。gmond 带来的系统负载非常少，这使得它成为在集群中各台计算机上运行的一段代码，而不会影响用户性能。所有这些数据多次收集会影响节点性能。网络中的 “抖动”发生在大量小消息同时出现时，可以通过将节点时钟保持一致，来避免这个问题。 gmetad可以部署在集群内任一台节点或者通过网络连接到集群的独立主机，它通过单播路由的方式与gmond通信，收集区域内节点的状态信息，并以XML数据的形式，保存在数据库中。由RRDTool工具处理数据，并生成相应的的图形显示，以Web方式直观的提供给客户端。 工作原理： Ganglia包括如下几个程序，他们之间通过XDR(xml的压缩格式)或者XML格式传递监控数据，达到监控效果。集群内的节点，通过运行gmond收集发布节点状态信息，然后gmetad周期性的轮询gmond收集到的信息，然后存入rrd数据库，通过web服务器可以对其进行查询展示。 安装ganglia网上示例很多，对该部分的翻译后续再跟进。 配置ganglia默认的配置仅仅能使ganglia工作，如果了解更多的配置项，能帮助你更好的使用ganglia做监控部署。 gmod安装在每个想监控的节点上，与操作系统交互获取度量信息（cpu使用率、内存、网络以及其他可通过自定义拓展的度量）并与集群内其他节点共享。每个在集群内的gmod实例知晓所有gmond所在节点的度量值，并通过XML格式的dump对外提供访问，gmetad通过gmond的连接端口连接。 拓扑结构gmond的默认拓扑结构采用广播的方式(multicast)，意味着所有集群内节点发送并接受度量信息，并以hash table的结构保存到各自的内存数据库中，包括所有集群节点的度量信息。如下图所示： 上图图解最重要的是与gmond deamon全然不同的性质。在内部，gmond发送和接受两种行为是无关联的（正如图中垂直虚线所示）。gmond不会自我交互，它只会向网络中发送度量信息。任何本地节点的信息获取都会经过sender传输到网络中，再由receiver从网络中收集。 这种拓扑对大多数场景适用，但某些案例下，指定少数监听者比每个节点都监听集群内度量信息要更行之有效，因为每个节点都监听会浪费额外的cpu，更多细节详见第三章。 通过“聋哑”模式，如下图，可以消除大集群内的过度联系。聋人模式和哑人模式使一些gmond按特定的模式工作，如收集或者发送。哑人模式意味着节点不对外传输数据，但收集集群内其他节点的度量信息。聋人模式意味着该实例不接受网络中的度量信息，但它不是哑巴，它会持续向网络中的其他监听节点发送度量信息。 并非所有的拓扑模型都要求使用广播。当广播不是第一选择的时候，聋哑模式的拓扑可由UDP单播实现: 或者，可以混合使用“聋哑”模式和默认的拓扑创建适合你环境的系统架构。唯一的拓扑要求如下所述： 在集群内至少有一个gmond实例负责接收网络中的所有度量信息。 gmetad必须定期轮训gmond以拉去集群状态信息。 然而真实实践中，不具备广播连通性的节点不需要配置成”deaf”模式；他们可以使用127.0.0.1地址为自己发送消息，并保留自己的本地度量信息。这可以利用于节点自己发送TCP探针（XML）来排查故障。 2.配置文件可以用以下gmond命令生成默认的配置文件： user@host:$ gmond -t 配置文件由多个部分组成，用花括号包裹，这可以大致分为两个逻辑目录。第一部分包含节点与集群的配置；另一部分包括度量信息的收集和定时策略。 所有的配置属性大小不敏感，如以下例子是相等的名称： name NAME Name NaMe 有些配置部分是可选的；一些配置是必填的。有些可以定义多次，有些只能配置一次。有些配置可以包含子选项配置。 当配置复杂时，有些内部指令可以将gmond.conf分离到多个文件中，并支持类型通配。如： include (&apos;/etc/ganglia/conf.d/*.conf&apos;) 将会命令gmond加载/etc/ganglia/conf.d/路径下所有以.conf为后缀的配置文件。 PS：为了快速开始，你所需要配置的仅仅是cluster部分下的name属性，其他属性可以全部默认。 配置文件使用第三方API工具libconfuse解析，采用libconfuse正常的格式规范。值得说明的是，boolean类型的值可以是yes,true,on；与他们相对的是no,false,off。布尔类型是大小写不敏感的。 有以下八个部分配置节点自身属性: Section: globals.配置守护线程自身的通用属性，配置文件中只能够配置一次。以下是Ganglia3.3.1的默认配置：123456789101112131415globals &#123; daemonize = yes setuid = yes user = nobody debug_level = 0 max_udp_msg_len = 1472 mute = no deaf = no allow_extra_data = yes host_dmax = 86400 /*secs. Expires (removes from web interface) hosts in 1 day */ host_tmax = 20 /*secs */ cleanup_threshold = 300 /*secs */ gexec = no send_metadata_interval = 0 /*secs */&#125; daemonize (boolean)当配置为true时，gmond在后台并行运行。当配置为false时，你可以使用deamontools等守护线程管理工具运行。 setuid (boolean)当设置为true时，gmond以user属性下的有效uid运行，否则不改变有效用户。 debug_level (integer value)当设置为0时，gmond正常运行。等级越高，输出的日志信息越丰富。 max_udp_msg_len (integer value)udp单包的最大长度，不建议修改。 mute (boolean)当设置为true时，gmond不会发送数据，忽略其他的配置指令。只用于收集其他gmond信息，但仍然会响应如gmetad轮询者的请求。 deaf(boolean)当设置为ture时，gmond不会接收数据，忽略其他配置指令。当置于大规模集群中，或者HPC敏感的网格中，CPU消耗成为不得不考虑的因素时，通常节点会配置为deaf模式以确保集群之间的交互降到最低。在这种情境下，部分节点设置为mute专注于收集。如此一来，mute节点的状态信息并不用于集群总状态的评估。它们的作用只是用于收集，所以他们的节点状态会污染集群状态信息。 allow_extra_data (boolean)当设置为false时，gmond不会发送标记为EXTRA_ELEMENT和EXTRA_DATA的XML部分。如果你使用自己的前端平台，这个参数可以有效节省带宽。 host_dmax (integer_value in seconds)代表“delete max”，当设置为0时，gmond永远不会从他们的列表中删除节点，即时某些远程节点丢失报告对量。如果host_dmax 设置为比0大的自然数，gmond会在超过这个时间后刷新host列表。 host_tmax (integer_value in seconds)代表“timeout max”。gmond更新host状态的最大等待时间。因为消息会在网络中丢失，所以gmond会在该超时时间未接收到数据后判定该节点down掉。 cleanup_threshold (integer_value in seconds)gmond清理过期数据的最大时间。 gexec (boolean)当设置为true，gmond允许节点执行gexec job，这个方法要求本节点gexecd已运行并且安装了合适的键。 send_metadata_interval (integer_value in seconds)设置gmond发送或重发包含度量信息的元数据包的时间间隔。默认设置为0，这意味着gmond只有当启动时，或者别的远程节点请求时才会发送数据包。当一个新节点gmond加入集群时，需要通知自己和其他所有节点当前的支持状态。在广播模式下，这不是个问题，但是单播模式下，该时间间隔必须设置，表示两次发送数据的时间间隔。 module_dir (path; optional)指定度量收集模块所在的目录位置。如果忽略，则默认是编译时期的配置项：–with-moduledir。这个配置项，默认是Ganglia目录下的libganglia所在目录，运行如下指令生成默认gmond可发现的配置文件 #gmond -t Section: cluster.每个gmond节点向集群报告信息都通过cluster部分的配置。默认值设置为”unspecified”；默认值是系统可用的，该部分在配置文件中只能配置一次。以下是默认配置：123456cluster &#123; name = &quot;unspecified&quot; owner = &quot;unspecified&quot; latlong = &quot;unspecified&quot; url = &quot;unspecified&quot;&#125; name (text)指定集群名称。当节点轮训拉取xml描述的节点状态信息时，该名称会被插入到CLUSTER部分。gmetad会根据这个值在拉取时归并到不同的RRD文件中存储。该配置项取代了在gmetad.conf中的cluster name配置项。 owner (text)配置集群管理员。 latlong (text)指定集群在地球上的GPS经纬度坐标。 url (text)指定集群的特定URL地址访问信息，如集群目的和使用明细。 Section: host.指定运行该gmond实例的host地址。只有一个配置项：123host &#123; location = &quot;unspecified&quot;&#125; location (text)节点地址，rack,U[,blade]格式也是可用的。 Section: UDP channels.配置gmond节点与其他节点对话的UDP发送/接收渠道。集群通过UDP通道交互，这意味着，所谓集群只是gmond节点直接的发送和接收消息的通道组成。默认情况下，每个gmond节点通过UDP广播向其他节点广播度量信息，其他节点类似。这样很容易启动和维护：每个节点在集群中共享广播地址，并且新增节点自动发现。然而，当我们回顾之前的deaf and mute模式，某些情况下需要单独指定单播地址。由此，每一个gmond的发送和接收频道需要针对当前环境进行配置。每个发送通道的配置定义了一个新的发送自身度量信息的方式，每个接收通道的配置定义了从其他节点接收度量信息的方式。通道可以通过IP4-IP6进行单播或者广播。 记住，一个gmond节点不可向多个集群发送度量信息，也不要试图从其他集群节点接收度量信息。 UDP通道通过udp_(send|receive)_channel部分创建。默认发送通道如下：123456udp_send_channel &#123; #bind_hostname = yes mcast_join = 239.2.11.71 port = 8649 ttl = 1&#125; bind_hostname (boolean; optional, for multicast or unicast)配置是否通过机器名绑定。 mcast_join (IP; optional, for multicast only)当指定时，gmond将会通过创建udp连接并且加入广播组，该配置创建广播渠道并与host配置二选一。 mcast_if (text; optional, for multicast only)指定时，gmond通过指定接口发送数据。如：eth0 host (text or IP; optional, for unicast only)指定发送数据地址，与mcast_join二选一。 port (number; optional, for multicast and unicast)gmond发送数据使用端口，默认8649 ttl (number; optional, for multicast or unicast)time-to-live存活时间，该配置项对广播环境 尤其重要，用于限制度量信息的有效时间，越高的值，则容忍性越大。 如下是默认的接收通道配置：12345udp_recv_channel &#123; mcast_join = 239.2.11.71 port = 8649 bind = 239.2.11.71&#125; mcast_join (IP; optional, for multicast only)当指定时，gmond将从该IP所在的广播群组中接收广播信息，如果不指定广播属性，gmond将会通过特定端口创建UDP单播服务。 mcast_if (text; optional, for multicast only)同上； bind (IP; optional, for multicast or unicast)指定后，gmond将会和本地地址绑定。 port (number; optional, for multicast or unicast)接收端口，默认8649 family (inet4|inet6; optional, for multicast or unicast)ip版本，默认inet4。如果想监听ipv4和ipv6两个网络，需要配置两个接收渠道。 acl (ACL definition; optional, for multicast or unicast)access control list：细粒度的接受渠道控制。详见“Access control”章节。 Section: TCP Accept Channels.gmond与gmetad或者其它轮询者交互通过TCP通道。可选如下配置项，默认如下：123456789tcp_accept_channel &#123; port = 8649&#125;bind (IP; optional)port (number)family (inet4|inet6; optional)interface (text; optional)acl (ACL definition; optional) Access control. 即acl，udp_recv_channel和tcp_accept_channel 的配置项。这个配置可以指定具体地址或者地址范围来添加gmond的连接许可。如下是个ACL示例：12345678910111213acl &#123; default = &quot;deny&quot; access &#123; ip = 192.168.0.0 mask = 24 action = &quot;allow&quot; &#125;access &#123; ip = ::ff:1.2.3.0 mask = 120 action = &quot;deny&quot; &#125;&#125; 配置遵从第一优先级。mask可指定路由范围。 Optional section: sFlow. sFlow是产品级的管理高速网络交换的技术。起初设想嵌入网络硬件内，现在存在于操作系统级别，如同其他应用一样如tomcat等web容器。gmond可以配置为成为sFlow的收集器，打包sFlow的数据包并发送给gmetad。在第八章中详细介绍。该配置全部可选，以下是默认配置：12345678910#sflow &#123;# udp_port = 6343# accept_vm_metrics = yes# accept_jvm_metrics = yes# multiple_jvm_instances = no# accept_http_metrics = yes# multiple_http_instances = no# accept_memcache_metrics = yes# multiple_memcache_instances = no#&#125; udp_port (number; optional)用于接收sFlow数据的端口。 Section: modules.该配置包含了加载度量模块的必须参数。gmond可收集所有动态加载的可扩展的度量模块。详见第五章。每个模块至少包含一个module子目录。该子目录由5个属性组成。默认配置包括所有已安装的度量插件，所以除非你有新增的度量插件，不然无需更改。示例如下：123456789101112131415modules &#123; module &#123; name = &quot;example_module&quot; language = &quot;C/C++&quot; enabled = yes path = &quot;modexample.so&quot; params = &quot;An extra raw parameter&quot; param RandomMax &#123; value = 75 &#125; param ConstantValue &#123; value = 25 &#125; &#125;&#125; name (text)如果使用c/c++实现，则该参数由模块结构决定。如果使用phthon等解释性语言编写，则由源文件决定。 language (text; optional)文件源码的实现语言，默认是c/c++，目前只支持c/c++或者python。 enabled (boolean; optional)方便该度量插件的启停。默认为yes； path (text)gmond加载度量插件的路径(c/c++动态加载)，如果不是绝对路径，则在前补上globals模块下的module_path属性。 params (text; optional)加载插件时的string参数。 Section: collection_group.该目录指定gmond收集那些度量信息，以及收集和广播的频率。你可以 尽可能多的将待收集的度量信息分组。每个分组至少包含一个 metric 模块。这是根据采样间隔做的逻辑分组。在gmond.conf下的不会影响web下的分组结果，默认配置如下：1234567891011121314151617181920212223collection_group &#123; collect_once = yes time_threshold = 1200 metric &#123; name = &quot;cpu_num&quot; title = &quot;CPU Count&quot; &#125; &#125;collection_group &#123; collect_every = 20 time_threshold = 90 /* CPU status */ metric &#123; name = &quot;cpu_user&quot; value_threshold = &quot;1.0&quot; title = &quot;CPU User&quot; &#125; metric &#123; name = &quot;cpu_system&quot; value_threshold = &quot;1.0&quot; title = &quot;CPU System&quot; &#125;&#125; collect_once (boolean)某些度量信息除非重启否则不会改变，如操作系统类型，cpu核数等。这些参数只需要启动时采集一次即可。该参数和collect_every互斥。 collect_every (seconds)频繁轮训采集时间，如cpu_user，cpu_system每20秒采集一次。 time_threshold (seconds)最大等待时间，gmond发送collection_group数据到所有udp_send_channels的时间。 name (text)度量信息在度量模块中的名称。典型的，每个度量模块定义多个度量信息名称，一个可选的name可以是name_match，如果使用name_match代替name，可以匹配多个度量名称，例如：namematch = “multicpu([a-z]+)([0-9]+)” value_threshold (number)每次收集度量信息，新值会和上一次的值进行比对。如果发生变化并且当前值大于配置值，则整个收集群组会发送到udp_send_channels定义的通道内。 title (text)一个用于web展示的用户友好的度量标题。 gmetadgmetad,the Ganlia Meta Daemon，安装在运行了收集度量信息的gmond节点之上，负责度量信息的收集和聚合。默认情况下，gmetad收集并聚合度量信息存储到RRD文件，但可以配置gmetad向其他系统汇总数据，如Graphite。 gmetad监听tcp端口8651，连接远程的gmetad并提供授权节点的xml dump状态文件。通过8652tcp端口响应其他节点的请求。交互的设备接受简易的子树和xml网格状态的总览。gweb通过使用这些查询在展现不适合存储在RRD中的数据，比如操作系统版本信息。 gmetad拓扑一个最简单的拓扑结构如下图所示，只存在一个gmetad负责轮训多个gmond实例: 高可用性是通常的需求也比较容易实现。如下图所示，两个gmetad和多个gmond实例。gmetad如果从node1拉取不到，将会从node2拉取。两个gmetad也会同时工作: gmetad并未限制轮训gmond，也可以拉取gmetad以创造另一个gmetad层级。如下图： 在更大的集群中，IO成为性能瓶颈，rrdcached作为gmetad和RRD文件的中间缓存，如图: gmetad.confgmetad.conf配置文件由单行属性和相对应的值组成。名称大小写不敏感，但value不同。如下所示属性表示的是相同的名称： name NAME Name NaMe 大多数属性是可选的；另外的是必须的。有些可被定义多次，有些只能被定义一次。 The data_source attribute. data_source是gmetad的核心配置。每一行data_source描述一个gmond集群或者一个由gmetad负责收集和聚合的网络。gmetad可以自行区分是一个cluster还是一个由gmetad主导的网格，所以data_source对二者都是相等的。如果gmetad发现data_source指向一个cluster ，它从data_source将维持完成的轮训列表。否则，gmetad会认为data_source指向网格，它只保存RRD的相关概要信息。 设置scalable属性为false，会强制gmetad保持完整的RRD文件集合以用于网格数据源。 以默认配置文件为例： data_source &quot;my cluster&quot; 10 localhost my.machine.edu:8649 1.2.3.5:8655 data_source &quot;my grid&quot; 50 1.3.4.7:8655 grid.org:8651 grid-backup.org:8651 data_source &quot;another source&quot; 1.3.4.8:8655 1.3.4.8 每个data_source由三部分构成。第一部分唯一标识该数据源。第二部分指定轮训时间间隔，单位是秒。第二部分表示gmetad轮训数据的空格分割的host地址列表，可以使用IP或者DNS识别的域名。最后一部分表示tcp端口，默认8649。 gmetad将按顺序检查列表中每个Host，带着第一个节点的状态信息做出响应。所以没必要在data_source中列举集群内所有节点。两三个既能保证数据不会出错。 gmetad daemon behavior. 属性列举如下： gridname (text) 字符串类型，唯一标识一个gmetad网格。这个字符串不能与gmond集合中的名称冲突。在gmond.conf（cluster中的配置项{name=”XXX”}）用于表示哪些特定的gmond实例负责收集。而gridname属性将会用Grid标签包裹数据源的数据。可以定义为data_source的收集者。 authority (URL)网格有效的URL，用于其他gmetad实例访问当前数据源的图表信息，默认地址为：http://hostname/ganglia/ trusted_hosts (text)gmetad的信任地址，localhost是用被信任的，空格分割。 all_trusted (on|off)设置为on则重写trusted_hosts配置，任何节点都被信任。 setuid_username (UID)gmetad使用的用户id，默认是nobody。 setuid (on|off)是否禁用uid。 xml_port (number)gmetad的监听端口，默认8651. interactive_port (number)gmetad交互端口，默认8652。与上个配置项对应。 server_threads (number)连接到监听端口的最大连接数。默认为4。 case_sensitive_hostnames (1|0)在早期的版本中，RRD文件使用大小写敏感的hostname创建，但如今已不在使用。3.2版本后默认为0。 RRDtool attributes. 配置RRD文件的创建和处理。 RRAs (text)These specify custom Round Robin Archive values. The default is (with a “stepsize” of 15 seconds): “RRA:AVERAGE:0.5:1:5856” “RRA:AVERAGE:0.5:4:20160” “RRA:AVERAGE:0.5:40:52704” The full details of an RRA specification are contained in the manpage forrrdcreate(1). umask (number)Specifies the umask to apply to created RRD files and the directory structure containing them. It defaults to 022. rrd_rootdir (path)Specifies the Graphite support. 可以将gmetad收集的度量数据全部导出到Graphite，一个第三方的开源的度量信息存储和可视化展示工具，配置参数如下： carbon_server (address)hostname或者ip，远程的daemon地址。 carbon_port (number)远程端口号，默认2003。 graphite_prefix (text)Graphite使用点号分割的路径组织和引用度量信息，所以更合适写一个前缀来表示描述度量信息。如datacenter1.gmetad carbon_timeout (number)gmetad等待Graphite的响应时间，单位毫秒。这个设置十分重要，因为gmetad的sender不是线程的并且会产生阻塞。默认500。 gmetad interactive port query syntax. 正如前面所提，gmetad监听tcp端口8652用于响应请求信息。这个请求基础的功能是获取grid中他们感兴趣的xml类型的dump状态信息。 通过文本协议，如SMTP和HTTP。请求有层级结构，以（/）斜线开始。比如如下请求会返回所有度量信息： / 如果要更明确请求内容，可以指定集群名称，如： /cluster1 如果要更明确节点内容，可以指定节点名称，如： /cluster1/host1 请求也可以通过指定后缀参数设置过滤器来修正度量值，如你可以获取cluster1的概要信息： /cluster1?filter=summary gweb相比ganglia的三个部分而言，gweb是最需要配置的组件。实际上，你不需要改变任何参数，gweb即可运行完整功能的web UI。 Apache virtual host configuration 尽管gweb本身不需要配置，但一些web容器想运行gweb需要作出部分配置。每个需要支持PHP的web容器需要做以下工作，还有许多是本书中未涉及的web配置参数。Apache Web Server是常用的web容器。假设gweb安装在/var/www/html/ganglia2，域名为 myganglia.example.org，则配置如下：1234567NameVirtualHost *.80&lt;VirtualHost *:80&gt;ServerName myganglia.example.orgServerAlias mygangliaDocumentRoot /var/www/html/ganglia2# Other directives here&lt;/VirtualHost&gt; 这只是一个简单的例子，更多详见：http://httpd.apache.org/docs/2.0/vhosts/ gweb options gweb的配置通过conf.php文件。实际上这个文件覆盖了默认文件conf_default.php。该文件在web目录的根目录下。该文档已编写完善，超过80个配置项不需要一一配置，只需使用时修改其中重要的几个即可。 该文件，正如名称所讲，是由许多参数组成的PHP脚本，不像其他的配置文件，参数有多行组成。这些属性名都是以$conf这种gweb格式组成，大小写敏感，看起来像PHP数组。如下参数表示gweb使用的RRDtool所在目录： $conf[&apos;rrdtool&apos;] = &quot;/usr/bin/rrdtool&quot;; 所有的参数都是必须的，也有一些被定义多次，也有被定义一次，也有引用其他的变量值，如： $conf[&apos;rrds&apos;] = &quot;${conf[&apos;gmetad_root&apos;]}/rrds&quot;; Application settings.该目录下的参数影响gweb的基础功能，它自己的家目录，比如，RRDs或者templates。这些很少被用户修改但偶尔会被提及。 templates (path)指定gweb的templates路径。就像一个站点的皮肤样式。 graphdir (path)指定定义图表的json文件所在路径。如下章所讲，用户会用json自定义图表样式，并将其存放在该目录下，用于web的UI展示。 rrds (path)指定RRD文件的所在目录。 又如第七章所提到的，不同的Nagios的特性在gweb的conf.php文件中集成。所以Nagios可以通过请求gweb获取度量信息，而不是Nagios Service Check Acceptor(NSCA)和Nagios Remote Plugin Executor (NRPE)。 Look and feel.gweb可以配置一次显示的图表数量(max_graphs)，也可以用来指定列数量和host视图。也有一些布尔类型的配置影响UI的默认行为，如 metric_groups_initially_collapsed。 config.php文件定义了大量样式，以及自定义时间范围。 Security.该属性参数如下： auth_system (readonly|enabled|disabled) gweb做了简单的安全认证机制，允许或禁止个别用户对部分应用功能的访问。如果设置为enabled则为可用。 Advanced features.参数如下：rrdcached_socket (path)指定rddcached的socket地址，用于高并发下的缓存策略。 graph_engine (rrdtool|graphite)gweb可以使用Graphite代替RRDtool作为图形引擎。该配置要求你已安装Graphite和Graphite webapp在该服务器上。详见：sourceforge.net/apps/trac/ganglia/wiki/ganglia-web-2#UsingGraphiteasthegraphingengine 部署运行到此为止，ganglia已经安装配置完成，是时候运行一下它们了！验证它们的基础功能是否完善并确保它们之间的通讯完成。 Starting Up the Processes 虽然没必要保证启动的先后顺序，如果按此处推荐顺序启动，能避免对元数据转换成udp聚合包的等待延迟，并且用户不会再web端看到错误数据。 如果你使用UDP单播模式，先启动UDP的收集节点。这样能确保该收集器能收集到各节点第一次发送的元数据。 启动其他的gmond实例。 如果你使用了rddcached，启动它。 从最低的层级开始启动gmetad。 启动其他层级的gmetad。 启动apache web server，比gmetad后启动，如果PHP脚本不能连接gmetad，可通过端口8652监控。 Testing Your Installationgmond和gmetad都监听tcp端口，为了测试gmond，使用telnet： user@host:$ telnet localhost 8649 作为回复，gmond会输出一段xml格式的dump信息，包含其度量信息。如果gmond是deaf模式或者mute模式，会返回一个空的xml文档，仅仅含有cluster标签。测试gmetad可以使用 user@host:$ telnet localhost 8651 一个有效的gmetad会返回一段xml格式的dump度量信息。详见第六章，了解更多验证程序状态的方法。 Firewalls防火墙问题是初装ganglia最普遍的问题，我们整理问题如下： gmond默认使用广播模式，所以跨越子网的集群需要配置单播的发送者和监听者，在之前的拓扑章节有介绍。如果gmond必须穿过防火墙与其他节点交互，允许端口udp/8649。对于广播模式，路由和防火墙必须支持IGMP协议。 gmond从端口TCP 8649监听gmetad连接。如果gmetad必须穿过防火墙，则保证其gmond的tcp 8649端口畅通。 gmetad使用tcp 8651，8652。前者类似于gmond的8649端口，后者作为“交互查询端口”用于响应指定的查询请求。被gweb使用，且通常与gmetad安装在同一台机器，所以除非你有使用更多的集成特性，如Nagios集成，或者有自定义的查询gmetad的脚本，不然不需要有防火墙的ACLs。 gweb运行在web容器中，通常监听80或者443端口(如果你使用SSL，则443)。如果web服务器被防火墙隔离，那么开放Tcp80和tcp443端口。 如果ganglia集成了sFlow收集器，并且每个sFlow收集器都要与gmond交互 ，为gmond的监听开放udp 6343端口。]]></content>
      <categories>
        <category>Ganglia</category>
      </categories>
      <tags>
        <tag>监控</tag>
        <tag>ganglia</tag>
      </tags>
  </entry>
</search>
